{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qfnk1NoSihAb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.core.fromnumeric import shape, size\n",
        "from random import random, randint, uniform\n",
        "# from keras.datasets import mnist\n",
        "# import opendatasets as od\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uaqAPZUrim71"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):  \n",
        "  return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def loss(y_predict, y):\n",
        "    return (-y* np.log(y_predict) - (1 - y)*np.log(1 - y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mXnN74--ipJe"
      },
      "outputs": [],
      "source": [
        "class Logistic_Regression:\n",
        "    def __init__(self):\n",
        "        self.weight =0\n",
        "\n",
        "    def feedForward(self, inputs):\n",
        "        inputs = np.concatenate([inputs, np.ones((len(inputs), 1))], axis= -1)\n",
        "        self.outputs= []\n",
        "        self.outputs  = sigmoid(np.dot(inputs, np.array(self.weight)))\n",
        "        return self.outputs\n",
        "\n",
        "    def fit(self, inputs, target, iterations=100, learning_rate=0.001):\n",
        "        hold_inputs = np.concatenate([inputs, np.ones((len(inputs), 1))], axis= -1)\n",
        "        self.weight = np.random.rand(np.shape(inputs)[1]+1)\n",
        "        for i in range(iterations):\n",
        "            self.feedForward(inputs)\n",
        "            delta=np.dot((self.outputs- target), hold_inputs)/target.size\n",
        "            dw = learning_rate*delta\n",
        "            self.weight = self.weight - dw \n",
        "            # if(i%100 == 0):\n",
        "                # print(accuracy_score(target, self.outputs> 0.5))\n",
        "                #print(loss(self.outputs, target))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY1_MZd_jeUK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/smoke-detection-dataset/smoke_detection_iot.csv\")\n",
        "df.drop(['Unnamed: 0', 'UTC'], axis=1, inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAgU4LLhjn2h"
      },
      "outputs": [],
      "source": [
        "y = df.pop('Fire Alarm').to_numpy()\n",
        "X = df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yYZLST3_jzWa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import log,dot,exp,shape\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "x,y = make_classification(n_features=4,n_classes=2)\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy2oYb4xirgB",
        "outputId": "553cb7ef-d57b-4b3b-ce42-ea8a8b814af0"
      },
      "outputs": [],
      "source": [
        "lr= Logistic_Regression().fit(X_train[:1000], y_train[:1000], iterations=400)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wi4GrcYbESEN"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "scaler = StandardScaler()\n",
        "x_train = x_train.reshape(x_train.shape[0],-1)\n",
        "x_test = x_test.reshape(x_test.shape[0],-1)\n",
        "x_train = x_train[[x in [0,1,2] for x in y_train]]\n",
        "y_train = y_train[[x in [0,1,2] for x in y_train]]\n",
        "x_test = x_test[[x in [0,1,2] for x in y_test]]\n",
        "y_test = y_test[[x in [0,1,2] for x in y_test]]\n",
        "x_train_scaled = scaler.fit_transform(x_train) \n",
        "x_test_scaled = scaler.transform(x_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1pkIRJcGarr",
        "outputId": "87fcb030-30af-4b16-c08e-6eabbce0aaa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.806\n",
            "0.695\n",
            "0.876\n"
          ]
        }
      ],
      "source": [
        "models = []\n",
        "for c in range(3):\n",
        "  \n",
        "  model = Logistic_Regression()\n",
        "  model.fit(x_train_scaled[:3000], (y_train == c).astype('int')[:3000], iterations =2000)\n",
        "  models.append(model)\n",
        "  outs = model.feedForward(x_test_scaled[:1000])\n",
        "  # print(pd.Series(outs > 0.5).value_counts())\n",
        "  print(accuracy_score((y_test == c).astype('int')[:1000], outs>0.5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOukDHUCLuC7",
        "outputId": "787dba23-131e-424b-80fc-795609cb2f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8786145535430568\n"
          ]
        }
      ],
      "source": [
        "def predict_one_vs_all(models, x_test, y_test):\n",
        "  preds = []\n",
        "  for m in models:\n",
        "    outs = m.feedForward(x_test)\n",
        "    preds.append(outs)\n",
        "  preds = np.array(preds).T\n",
        "  print(accuracy_score(y_test,  preds.argmax(-1)))\n",
        "predict_one_vs_all(models, x_test_scaled, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('DeepLearning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "36062c478ba8668154df998709043a294048a01eff82153ce1a7725f71761d6e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
